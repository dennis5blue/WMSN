\section{Related Work}
\label{sec::RelatedWork}
{\color{blue}
Recently, visual sensor networks (VSN) have caught much attention in different
research areas.
One of the most challenging research topics in VSN is the data transmission
issue, which is very different from the conventional scalar sensor
network~\cite{VsnChallenges}.
For example, a surveillance system might have a huge amount of radio resource
demand to provide the image/video transmission over a wireless communication
link.
The authors in~\cite{VehicleSurveillance} motivated the idea of intelligent
vehicle surveillance system for tracking multiple vehicles.
In their model, multiveiw cameras are installed to track vehicles from
different angle of view.
Therefore, in order to operate their system in real-time, there might have some
redundancy among the video transmission and hence motivates us to study how to
reduce the radio resource usage.

One way to exploit the redundancy among multiple surveillance cameras is
through a clustered summary, which is able to browse and search the video in an
efficient way~\cite{ClusteredSynopsis}.
The authors in~\cite{ClusteredSynopsis} argued that regular browsing the
surveillance videos is impossible, since the surveillance videos are often
endless.
Therefore, they improved the browsing efficiency by clustering similar
activities into a shorter video summary.
However, their work focused on the user space efficiency and did not mention
how to collect such huge amount of videos through the wireless communication
links.
In work~\cite{CameraSelection}, the authors reduced the amount of image data
that needs to be transmit over the network by selecting part of the cameras to
report their information.
The selection is based on each cameras' observation and the goal of selection
is to figure out the views that contribute most significantly to the desire
observation.
Our work, on the other hand, required all cameras in the network to transmit
its data while those cameras can reduce their own radio resource usage by
overhearing others' information.
The authors in~\cite{OVVV} and~\cite{VirtualReality} showed the possibility to
use a \emph{Virtual Video} as the test bed of a surveillance systems.
They collected image data from virtual video and used those image for further
investigation.
Therefore, in our work, we also use a $3$D modeling software to generate
quasi-realistic city views and try to reduce the transmission of those views.

Spatial correlation between cameras gives the surveillance networks leverage to
reduce the total amount of encoded bits for transmission.
The authors in~\cite{SpatialCorrelationModel} proposed a spatial correlation
model for cameras deployed in a neighborhood area.
In their model, the correlation of two cameras are determined by their
location and the difference of their sensing direction.
However, the camera views are more complicated so that the correlation cannot
be determined only by its geometric characteristic.
Hence, in order to provide a more realistic model, the work
in~\cite{RealisticModel} gives an investigation of the relation among cameras
through a multiview video coding software.
They analyzed the performance of H.264 multiview video coding of multiple
cameras and showed that the coding cost of two cameras raises as their angular
difference become larger.

One way to deal with the resource reduction problem is through the distributed
video coding~\cite{DVC}, which is based on the Slepian-Wolf's and Wyner-Ziv's
coding theorem.
Distributed video coding is different from the conventional video coding scheme
at both the encoder and decoder.
More specifically, it suggests an encoder encodes individual frames
independently, but the decoder decodes them jointly, which means that the
previous frames are used as a side information at the decoder only.
The authors in~\cite{DVCinMVC} extended the idea of distributed video coding
into multiview systems with spatial correlation among cameras. 
In their work, side information can be generated by exploiting the spatial
correlation and redundancies between different camera's views while the decoder
has the complexity to decode those frames jointly.  
Our work, on the other hand, does not require the decoder to have so much
complexity.
We focus on an overhearing source coding scheme.
That is, each cameras has the possibility to overhear other cameras' frame so
that it can provide inter-frame processing to reduce its encoded bits.

The work in~\cite{MLS} considered overhearing in the wireless multimedia
sensor networks.
They made use of the model proposed in~\cite{SpatialCorrelationModel} and
solved a relaxed integer programming problem to determine a proper schedule for
reducing the most encoded bits.
In this paper, we define a more realistic correlation model and exploit a
\emph{correlation-aware scheduling algorithm} to achieve the same goal as the
optimization problem in~\cite{MLS}.
Simulation result will show that our proposed algorithm can have a better
performance than solving the relaxed optimization problem.
}