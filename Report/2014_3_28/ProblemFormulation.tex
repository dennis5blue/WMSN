\section{Correlation Analysis and Problem Formulation}
\label{sec:CorrelationAnalysisandProblemFormulation}
In this section, we first details how we analysis the correlation between
cameras in the wireless multimedia sensor network and then formulate our
problem.
\subsection{Correlation Analysis}
\label{sec:CorrelationAnalysis}
As we mentioned before, our purpose in this paper is to reduce the total
transmission time of the wireless multimedia sensor network.
To simplify our problem, we assume that all the cameras in the network need to
transmit its collected image to the aggregator and all the cameras can
overhear each other.
Therefore, our problem is to determine the transmission order so that all
cameras in the network can reference from the most correlated frame.

Given a set $V=\{1,2, \cdots N \}$ of cameras placed in a city, we now assume
that the number of transmission bits of camera $i$ equals $H(X_{i})$, and
$H(X_{i}|X_{j})$ is the number of transmission bits when camera $i$ reference
from camera $j$ to provide H.264 coding.
Note that since we assume that all the cameras in the city can hear others'
transmission; therefore, whether camera $j$ is an I-frame transmitter or not
does not influence the value of $H(X_{i}|X_{j})$.
More precisely, if camera $j$ is a P-frame transmitter referenced from camera
$k$, since camera $i$ can gather the data from both $j$ and $k$, it can first
decode the image of camera $j$ and then perform the H.264 encoding.
Hence, we can still obtain the same value of $H(X_{i}|X_{j})$.

To proceed, we now analysis the correlation between two cameras $i$ and $j$ as:
\begin{equation}
c_{ij} = \max \{ (1-\frac{H(X_{i}|X_{j})}{H(X_{i})}),0 \}.
\label{eq:correlationAnalysis}
\end{equation}
The reason why we take the maximum with $0$ is that $H(X_{i}|X_{j})$ can be
larger than $H(X_{i})$ when the scene gathered by camera $i$ and $j$ differs a
lot.
Therefore, in order to make the correlation level always non-negative, we set
${c_{ij}=0}$ when ${H(X_{i}|X_{j})>H(X_{i})}$.
Besides, $c_{ii}$ will not equals to $1$ since there still has some remaining
header in H.264 coding scheme even when using camera $i$ to predict itself. 

\subsection{Problem Formulation}
\label{sec:ProblemFormulation}
The total transmission time needed for the WMSN is highly related to the number
of encoded bits.
That is to say, if we first focus on a camera $i$, we can write the required
transmission time for camera $i$ as:
\[
T_{i} = 
\left\{\begin{tabular}{lp{5.4cm}ll}
\ensuremath{{H(X_{i})}/{C_{i0}}}, &if camera \ensuremath{i} transmits as
an I-frame, \\
\ensuremath{{H(X_{i}|X_{j})}/{C_{i0}}}, &if camera \ensuremath{i} transmits
as an P-frame and reference from camera \ensuremath{j},
\end{tabular}\right.
\]
where $C_{i0}$ is the channel capacity from camera $i$ to the data aggregator.
Therefore, the total transmission time is to sum up all the individual $T_{i}$,
${\forall i \in V}$ written as:
\begin{equation}
T = \sum_{i=1}^{N} T_{i}.
\label{eq:transmissionTime}
\end{equation}

The goal to minimize equation~\eqref{eq:transmissionTime} can be divided into
two sub-problems, including the I-frame selection problem and the P-frame
scheduling problem.
The I-frame selection problem is to choose part of the cameras in the set $V$,
and these selected cameras, say subset $S$, can save the most transmission bits
for the other cameras.
For all the cameras in $V \setminus S$, the P-frame scheduling problem is to
determine which camera to reference with.
